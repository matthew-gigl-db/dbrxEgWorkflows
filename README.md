# dbrxEgWorkflows - Databricks Example Workflows 
***

The purpose of this repo is a catchall of various Databricks Workflow examples based on real client requests.  Any code in the repo is for demo or training purposes only and is provided "as is."  It should not be used in production, but may be a starting point for development in a modern CI/CD process that includes system integration testing.   

## Available Examples:  

### delimtedForEach 

This workflow is an exmple of using the Databricks Workflow's forEach Task.  In this example we'll write a variable number of CSV files to an extract Volume in Unity Catalog based on the record count of the table we need to extract and max number of records allowed in each file.  


*** 

The 'dbrxEgWorkflows' project was generated by using the default-python template.

## Getting started

1. Install the Databricks CLI from https://docs.databricks.com/dev-tools/cli/databricks-cli.html

2. Authenticate to your Databricks workspace, if you have not done so already:
    ```
    $ databricks configure
    ```

3. To deploy a development copy of this project, type:
    ```
    $ databricks bundle deploy --target dev
    ```
    (Note that "dev" is the default target, so the `--target` parameter
    is optional here.)

    This deploys everything that's defined for this project.
    For example, the default template would deploy a job called
    `[dev yourname] dbrxEgWorkflows_job` to your workspace.
    You can find that job by opening your workpace and clicking on **Workflows**.

4. Similarly, to deploy a production copy, type:
   ```
   $ databricks bundle deploy --target prod
   ```

   Note that the default job from the template has a schedule that runs every day
   (defined in resources/dbrxEgWorkflows.job.yml). The schedule
   is paused when deploying in development mode (see
   https://docs.databricks.com/dev-tools/bundles/deployment-modes.html).

5. To run a job or pipeline, use the "run" command:
   ```
   $ databricks bundle run
   ```

6. Optionally, install developer tools such as the Databricks extension for Visual Studio Code from
   https://docs.databricks.com/dev-tools/vscode-ext.html.

7. For documentation on the Databricks asset bundles format used
   for this project, and for CI/CD configuration, see
   https://docs.databricks.com/dev-tools/bundles/index.html.
